# Context Whisperer

ContextWhisperer is an intelligent context management system for AI-assisted coding, designed to optimize the interaction between developers and Large Language Models (LLMs) in development environments.

## Problem

When working with AI coding assistants, context management is crucial but challenging:
- **Context starvation: Too little context**: The AI loses important details about the codebase, leading to inconsistent or incorrect suggestions
- **Context overload: Too much context**: The AI gets overwhelmed with information, resulting in confused or unfocused responses
- **Context switching**: Starting new chat sessions means rebuilding context from scratch, wasting time and computational resources

## Solution

ContextWhisperer runs a series of intelligent, manual prompts that:
1. Analyze your codebase systematically
2. Extract the most relevant contextual information
3. Generate optimized context summaries in the `.docs` directory
4. New AI chat sessions can quickly bootstrap by reading these context files

## Directory Structure

- `.prompts/`: Stores customizable prompt files for manual execution
  - `human/`: Prompts designed for human-readable output
  - `llm/`: Prompts optimized for LLM consumption
- `.docs/`: Contains the LLM-specific context markdown files generated by the prompts
- `docs/`: Reserved for human-readable documentation
  - `ai-generated/`: Contains AI-generated documentation designed for human developers

## How to Use

1. Review and customize the prompt templates in the `.prompts/` directory as needed
2. Execute prompts selectively by tagging files with `@` in Cursor's agent chat window
3. The AI will generate markdown files in the `.docs/` directory to provide context about the codebase for llms.
4. The human prompts will generate markdown files in the `docs/ai-generated/` directory to provide context about the codebase for humans.

## Philosophy

Context Whisperer emphasizes intentional and manual management of codebase context. Rather than relying on automated system prompts, it provides customizable, targeted utility prompts that users can execute selectively to generate the context most relevant to their needs.

## Pro Tips for AI Pair Programming

üí° **Use Local History**: When pair programming with AI, I strongly recommend using something like the ["Local History" extension by xyz](https://marketplace.visualstudio.com/items?itemName=xyz.local-history) in VS Code. AI assistants can sometimes move quickly or overwrite good code during the iterative development process. This plugin saves every code change, allowing you to recover previous versions if needed.

## How to install 

The most important files you want are under the `.prompts` directory. You can simply copy the `.prompts` directory into your project and then manually run the prompts as needed.

## Author

### Joe Devon
- üê¶ Social Media: @joedevon across platforms
- üéôÔ∏è Podcast: [A11yGenAI](https://www.youtube.com/@a11ygenai) - Accessibility and Gen. AI
- üì´ Newsletter: [Joe Dev On Tech](https://www.linkedin.com/newsletters/joe-dev-on-tech-7240847501472194560/) - Weekly technology insights

## Contributing

This project is in early development. Contributions and feedback are welcome!

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

